\chapter{Conclusion}\label{cha:conclusion}

This thesis analyzed large-scale network (blockchain) data and built a prototypical framework for community detection and observation for blockchain transaction network. State of the art community detection techniques and their underlying algorithms have been discussed in details at the beginning of the thesis. A handful of algorithms were discussed in details from a vast number of community detection techniques for the scope of this thesis.

This thesis proposed and implemented a prototypical framework that can detect communities in blockchain transactions and observe changes afterwards. This task was focused on two factors: 
\begin{itemize}
	\item run-time
	\item memory consumption
\end{itemize}
\noindent For any large-scale network data-set, it is obvious to find an optimized way to detect and track communities in blockchain data. So, the primary goal of the thesis evolved around the question - "How well an algorithm performs on large scale graph?". Secondary goal was to implement the proposed prototypical framework for observing changes in community detection. The proposed framework is implemented and evaluated in respect to run-time and memory consumption as well as detecting changes in detected communities at different time-stamps. The framework touches all the main objectives of this thesis from analyzing state of the art community detection techniques for large-scale networks, designing a prototypical framework to detect and observe changes in community to implementing and evaluation the framework.

Further study can be carried out on how to minimize the run-time even further for this framework. Determining the number of target communities will help reduce the time significantly. Proposed framework is a prototype that proves, it's possible to detect communities in blockchain data despite the anonymity of the transactions. It's possible to track communities and if necessary, a particular node's effect in the transaction network.

Blockchain gained popularity over the years and with it, the number of transaction also grew. It's a real challenge to process and analyze this huge data-set for community detection and observation. This framework is designed and implemented with the help of a medium capacity system\footnote{Intel(R) Core(TM) i5-3320M CPU @ 2.60GHz and 16 GB of RAM, with 64 bit UNIX Operating System}. Adding more feature modules to the framework is also possible and can help provide desired output depending on user's need. Framework can be further improved using a high end system, parallel processing or distributed computing can reduce the speed and memory consumption drastically, which will help to process more nodes at any given time-stamp.

